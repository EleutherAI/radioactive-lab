{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preliminaries</h1>\n",
    "<p>This codebase was originally created at Facebook by the team behind the following paper:</p>\n",
    "<p><strong>Radioactive data: tracing through training</strong><br />\n",
    "    <a href=\"https://arxiv.org/pdf/2002.00937.pdf\">https://arxiv.org/pdf/2002.00937.pdf</a>\n",
    "        </p>\n",
    "    \n",
    "<p>We have made some quality of life changes and created this notebook to help others learn faster. The demonstration\n",
    "will: </p>\n",
    "   <ol>\n",
    "       <li>Mark a certain subset of the CIFAR10 dataset (target data) using a resnet18 pretrained on imagenet (marking network)</li>\n",
    "       <li>Use the modified CIFAR10 dataset to train a new resnet18 (target network)</li>\n",
    "       <li>Attempt to detect radioactivity in the target network</li>\n",
    "    </ol>\n",
    "</p>\n",
    "<p><strong>Note:</strong><br/>\n",
    "In our example the marking network is pretrained on imagenet, while our target data is CIFAR10.\n",
    "According to section 5.5 of the paper, even a marking network trained on a different\n",
    "data distribution will output radioactive markings that are useful when applied to at least 10% of the dataset. \n",
    "This number could vary, we are just quoting the minimum radioactive data percentage shown in the paper. </p>\n",
    "<p>If the marking network was trained on the same data distribution it is likely that a lower percentage of the\n",
    "   target data would require marking to achieve the same p value in the detection stage.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating Radioactive Data (Image Marking)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prepare Dataset</h2>\n",
    "<p>First we download the CIFAR10 dataset which has 10 classes.</p>\n",
    "<p>Then we randomly choose an image class and sample a certain percentage of the images for saving to \"img/data\".</p>\n",
    "<p>After saving these images to \"img/data\" we also save a list of image paths to pass into <em>make_data_radioactive.py</em>.</p>\n",
    "<p>Currently <em>make_data_radioactive.py</em> doesn't support multi-class, so we only sample from a chosen class of images.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import random\n",
    "import PIL\n",
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "target_data_classes = 10 # 10 for CIFAR10 data\n",
    "\n",
    "# Download CIFAR10 dataset\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"data/datasets\", download=True)\n",
    "\n",
    "# Index images by class\n",
    "images_by_class = []\n",
    "for x in range(0, target_data_classes):\n",
    "    images_by_class.append([])\n",
    "\n",
    "for index, (img, label) in enumerate(train_set):\n",
    "    images_by_class[label].append(index)\n",
    "\n",
    "# Randomly choose an image class\n",
    "chosen_image_class = random.choice(list(range(0, target_data_classes)))\n",
    "print(f\"Randomly selected image class {chosen_image_class} ({train_set.classes[chosen_image_class]})\", flush=True)\n",
    "\n",
    "# Randomly sample images from that class\n",
    "data_marking_percentage = 1\n",
    "total_marked_in_class = int(len(images_by_class[chosen_image_class]) * (data_marking_percentage / 100))\n",
    "train_marked_indexes = random.sample(images_by_class[chosen_image_class], total_marked_in_class)\n",
    "\n",
    "# Save these images for marking to /data/img and build list file\n",
    "image_dir_path = \"data/img\"\n",
    "shutil.rmtree(image_dir_path, ignore_errors=True)\n",
    "os.makedirs(image_dir_path)\n",
    "\n",
    "print(f\"Saving {total_marked_in_class} images randomly sampled from class.\", flush=True)\n",
    "image_list = []\n",
    "for i in tqdm.tqdm(train_marked_indexes):\n",
    "    image, _ = train_set[i]\n",
    "    image_path = f\"{image_dir_path}/train_{i}.png\"\n",
    "    with open(image_path, 'wb') as fh:\n",
    "        img = image.save(fh)\n",
    "    image_list.append(image_path)\n",
    "     \n",
    "train_image_list_path = \"data/train_img_list.txt\"\n",
    "torch.save(image_list, train_image_list_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Download Marking Network And Save For Later</h2>\n",
    "<p>The below confused me at first. All <em>make_data_radioactive.py</em> is doing is spooling up a new\n",
    "torchvision.models.[architecture](marking_network_classes) and loading the state dictionary from the pretrained model, in\n",
    "this case trained on ImageNet with 1000 classes. After this occurs the fully connected layer is just removed anyway.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "marking_network_output_dim_pre_classifier = 512 # Used Further On\n",
    "marking_network_classes = 1000\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "torch.save({\n",
    "    \"model\": resnet18.state_dict(),\n",
    "    \"params\": {\n",
    "      \"architecture\": \"resnet18\",\n",
    "      \"num_classes\": marking_network_classes,\n",
    "    }\n",
    "  }, \"data/pretrained_resnet18.pth\")\n",
    "print(\"Marking network saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Random Carriers</h2>\n",
    "<p>Generates a random array of shape (target_data_classes, marking_network_output_dim_pre_classifier). \n",
    "In terms of the paper, this would be a concatenation of a random vector u for each class, see section 3 for details. The code in <em>make_data_radioactive.py</em> currently doesn't support multi-class, so it just slices this array to get a single random u.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "carriers = torch.randn(target_data_classes, marking_network_output_dim_pre_classifier)\n",
    "carriers /= torch.norm(carriers, dim=1, keepdim=True)\n",
    "print(\"Carrier Shape:\", carriers.shape)\n",
    "torch.save(carriers, \"data/carriers.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Run make_data_radioactive.py</h2>\n",
    "<p>The original code used input parameters but I have converted this to a config file out of taste preference.</p>\n",
    "<p><strong>img_list</strong> must be the same as <strong>train_image_list_path</strong> above</p> <br/><strong>carrier_id</strong> is irrelevant as multi-class is not currently supported, by setting it to 0 we just grab the first random u vector out of the carriers array created above.\n",
    "\n",
    "<p>Training (marking) will take about 10 minutes for 50 CIFAR images on a quad core CPU @ 4ghz. GPU would be way faster.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clear the experiment directory\n",
    "dump_path = \"data/dump\"\n",
    "shutil.rmtree(dump_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config_make_radioactive.toml\n",
    "dump_path = \"data/dump\"\n",
    "exp_name = \"bypass\"\n",
    "exp_id = \"\"\n",
    "img_size = 256\n",
    "crop_size = 224\n",
    "data_augmentation = \"random\"\n",
    "radius = 10\n",
    "epochs = 90\n",
    "lambda_ft_l2 = 0.01\n",
    "lambda_l2_img = 0.0005\n",
    "optimizer = \"sgd,lr=1.0\"\n",
    "carrier_path = \"data/carriers.pth\"\n",
    "carrier_id = 0\n",
    "half_cone = true\n",
    "img_list = \"data/train_img_list.txt\"\n",
    "img_paths = \":\"\n",
    "marking_network = \"data/pretrained_resnet18.pth\"\n",
    "debug_train = false\n",
    "debug_slurm = false\n",
    "debug = false\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run make_data_radioactive.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Inspect Our New Images</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "\n",
    "def loadImageRGB(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "    \n",
    "radioactive_images = glob.glob('data/dump/*.npy')\n",
    "radioactive_image_path = random.choice(radioactive_images)\n",
    "original_image_path = f\"data/img/{os.path.basename(radioactive_image_path)}\".replace(\"npy\", \"png\")\n",
    "\n",
    "original_img = loadImageRGB(original_image_path)\n",
    "radioactive_img = np.load(radioactive_image_path)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(original_img)\n",
    "ax1.set_title(\"Original Image\")\n",
    "ax2.imshow(radioactive_img)\n",
    "ax2.set_title(\"Radioactive Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training A Model</h1>\n",
    "<p>Work in progress...</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import re\n",
    "\n",
    "radioactive_image_paths = glob.glob('data/dump/*.npy')\n",
    "\n",
    "#search using regex\n",
    "content = {}\n",
    "for path in radioactive_image_paths:\n",
    "    img_id = re.search('[0-9]+', path)\n",
    "    content[img_id[0]] = path \n",
    "\n",
    "torch.save({\n",
    "  'type': 'per_sample',\n",
    "  'content': content\n",
    "}, \"data/radioactive_data.pth\")\n",
    "print(\"Radioactive image paths saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config_train_classif.toml\n",
    "dump_path = \"data/dump\"\n",
    "exp_name = \"bypass\"\n",
    "save_periodic = 0\n",
    "exp_id = \"\"\n",
    "nb_workers = 10\n",
    "fp16 = false\n",
    "dataset = \"cifar10\"\n",
    "num_classes = -1\n",
    "architecture = \"resnet18\"\n",
    "non_linearity = \"relu\"\n",
    "pretrained = false\n",
    "from_ckpt = \"\"\n",
    "load_linear = false\n",
    "train_path = \"radioactive_data.pth\"\n",
    "optimizer = \"sgd,lr=0.1-0.01-0.001,momentum=0.9,weight_decay=0.0001\"\n",
    "batch_size = 256\n",
    "epochs = 90\n",
    "stopping_criterion = \"\"\n",
    "validation_metrics = \"\"\n",
    "train_transform = \"random\"\n",
    "seed = 0\n",
    "only_train_linear = false\n",
    "reload_model = \"\"\n",
    "eval_only = false\n",
    "debug_train = false\n",
    "debug_slurm = false\n",
    "debug = true\n",
    "local_rank = -1\n",
    "master_port = -1\n",
    "use_cpu = true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train-classif.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
